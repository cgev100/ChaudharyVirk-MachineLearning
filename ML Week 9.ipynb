{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d56309d7-b650-433a-9a20-d374d15e3c4c",
      "metadata": {
        "id": "d56309d7-b650-433a-9a20-d374d15e3c4c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0fc0802c-8447-44ca-b322-5db980a221b8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0fc0802c-8447-44ca-b322-5db980a221b8",
        "outputId": "5eba62cd-9450-40ee-b155-216ef69f95a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.18.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "tf.__version__\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "opAQA6jRRg0P",
        "outputId": "47053273-4df2-4afe-a1d0-f2799ed34215"
      },
      "id": "opAQA6jRRg0P",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7430389f-b36e-4387-a922-ff912789c7bd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7430389f-b36e-4387-a922-ff912789c7bd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving shakespeare.txt to shakespeare.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2aa2c8c0-a56e-4c22-9438-5b656d6388e5",
      "metadata": {
        "id": "2aa2c8c0-a56e-4c22-9438-5b656d6388e5"
      },
      "outputs": [],
      "source": [
        "path_to_file = 'shakespeare.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7ea247aa-d2ca-4dd7-8c8f-88914fe7247d",
      "metadata": {
        "id": "7ea247aa-d2ca-4dd7-8c8f-88914fe7247d"
      },
      "outputs": [],
      "source": [
        "text = open(path_to_file, 'r').read()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1894d407-4490-4090-beb6-4a8271821366",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1894d407-4490-4090-beb6-4a8271821366",
        "outputId": "df7deef1-e802-470d-b4f0-e5d20a64f863"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ]
        }
      ],
      "source": [
        "print(text[:500])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "844dcb26-3ce8-40d1-abf2-56fa40d038a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "844dcb26-3ce8-40d1-abf2-56fa40d038a3",
        "outputId": "57090bca-367f-470f-8797-bf3a45b65f97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '|', '}']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "vocab = sorted(set(text))\n",
        "print(vocab)\n",
        "len(vocab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "55a7ed4b-e941-46bf-ba6c-e95ba52fddab",
      "metadata": {
        "id": "55a7ed4b-e941-46bf-ba6c-e95ba52fddab"
      },
      "outputs": [],
      "source": [
        "char_to_ind = {u:i for i, u in enumerate(vocab)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2b126132-b779-4844-baec-718c02c0382f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b126132-b779-4844-baec-718c02c0382f",
        "outputId": "0d6f61d5-43fb-4324-a3ca-e3c3bc5492f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '\"': 3,\n",
              " '&': 4,\n",
              " \"'\": 5,\n",
              " '(': 6,\n",
              " ')': 7,\n",
              " ',': 8,\n",
              " '-': 9,\n",
              " '.': 10,\n",
              " '0': 11,\n",
              " '1': 12,\n",
              " '2': 13,\n",
              " '3': 14,\n",
              " '4': 15,\n",
              " '5': 16,\n",
              " '6': 17,\n",
              " '7': 18,\n",
              " '8': 19,\n",
              " '9': 20,\n",
              " ':': 21,\n",
              " ';': 22,\n",
              " '<': 23,\n",
              " '>': 24,\n",
              " '?': 25,\n",
              " 'A': 26,\n",
              " 'B': 27,\n",
              " 'C': 28,\n",
              " 'D': 29,\n",
              " 'E': 30,\n",
              " 'F': 31,\n",
              " 'G': 32,\n",
              " 'H': 33,\n",
              " 'I': 34,\n",
              " 'J': 35,\n",
              " 'K': 36,\n",
              " 'L': 37,\n",
              " 'M': 38,\n",
              " 'N': 39,\n",
              " 'O': 40,\n",
              " 'P': 41,\n",
              " 'Q': 42,\n",
              " 'R': 43,\n",
              " 'S': 44,\n",
              " 'T': 45,\n",
              " 'U': 46,\n",
              " 'V': 47,\n",
              " 'W': 48,\n",
              " 'X': 49,\n",
              " 'Y': 50,\n",
              " 'Z': 51,\n",
              " '[': 52,\n",
              " ']': 53,\n",
              " '_': 54,\n",
              " '`': 55,\n",
              " 'a': 56,\n",
              " 'b': 57,\n",
              " 'c': 58,\n",
              " 'd': 59,\n",
              " 'e': 60,\n",
              " 'f': 61,\n",
              " 'g': 62,\n",
              " 'h': 63,\n",
              " 'i': 64,\n",
              " 'j': 65,\n",
              " 'k': 66,\n",
              " 'l': 67,\n",
              " 'm': 68,\n",
              " 'n': 69,\n",
              " 'o': 70,\n",
              " 'p': 71,\n",
              " 'q': 72,\n",
              " 'r': 73,\n",
              " 's': 74,\n",
              " 't': 75,\n",
              " 'u': 76,\n",
              " 'v': 77,\n",
              " 'w': 78,\n",
              " 'x': 79,\n",
              " 'y': 80,\n",
              " 'z': 81,\n",
              " '|': 82,\n",
              " '}': 83}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "char_to_ind\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "53fabb89-2cc6-4910-afa5-a371580e29d6",
      "metadata": {
        "id": "53fabb89-2cc6-4910-afa5-a371580e29d6"
      },
      "outputs": [],
      "source": [
        "ind_to_char = np.array(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7c56f298-7431-4349-baa4-e75e58163fc7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c56f298-7431-4349-baa4-e75e58163fc7",
        "outputId": "74406f67-1a7f-468d-d7a2-33edaba55fb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', ',', '-', '.', '0', '1',\n",
              "       '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '>', '?',\n",
              "       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
              "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
              "       '[', ']', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i',\n",
              "       'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v',\n",
              "       'w', 'x', 'y', 'z', '|', '}'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "ind_to_char\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a0ca5923-88a5-4bc8-854a-991205eb9dc8",
      "metadata": {
        "id": "a0ca5923-88a5-4bc8-854a-991205eb9dc8"
      },
      "outputs": [],
      "source": [
        "encoded_text = np.array([char_to_ind[c] for c in text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "eef33582-d009-4f44-bcad-70cc15be2087",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eef33582-d009-4f44-bcad-70cc15be2087",
        "outputId": "59888278-4ada-47ec-e24c-e2f5f71fd90f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  1,  1, ..., 30, 39, 29])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "encoded_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "0aa8a2e3-46fc-4cb7-88ad-e03d73a909f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0aa8a2e3-46fc-4cb7-88ad-e03d73a909f9",
        "outputId": "b288ce69-0adc-4b58-bba8-6b4a7722fe08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n                   '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "sample = text[:20]\n",
        "sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e1274eaf-c9ec-45d5-9684-bc6079cc7a33",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1274eaf-c9ec-45d5-9684-bc6079cc7a33",
        "outputId": "0fb4928c-d342-4e1b-ba8f-cc862a53a11b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "encoded_text[:20]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d3e96cdb-213f-496f-9b27-d69329b056b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3e96cdb-213f-496f-9b27-d69329b056b2",
        "outputId": "75b37322-3193-4925-aa0a-9fa074b1b52b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But as the riper should by time decease,\n",
            "  His tender heir might bear his memory:\n",
            "  But thou contracted to thine own bright eyes,\n",
            "  Feed'st thy light's flame with self-substantial fuel,\n",
            "  Making a famine where abundance lies,\n",
            "  Thy self thy foe, to thy sweet self too cruel:\n",
            "  Thou that art now the world's fresh ornament,\n",
            "  And only herald to the gaudy spring,\n",
            "  Within thine own bu\n"
          ]
        }
      ],
      "source": [
        "print(text[:500])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6b8fd7ae-93c1-4ad5-af3c-9a0e1915bd4a",
      "metadata": {
        "id": "6b8fd7ae-93c1-4ad5-af3c-9a0e1915bd4a"
      },
      "outputs": [],
      "source": [
        "line = \"From fairest creatures we desire increase\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "fca2880f-f3cf-47d0-bac8-65088ec3c972",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fca2880f-f3cf-47d0-bac8-65088ec3c972",
        "outputId": "630f9c1e-acd1-4ff2-b1dc-b10cfaf4b2b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "len(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "470f1999-35e0-4d3e-91a1-253f75da7cf3",
      "metadata": {
        "id": "470f1999-35e0-4d3e-91a1-253f75da7cf3"
      },
      "outputs": [],
      "source": [
        "part_stanza = \"\"\"From fairest creatures we desire increase,\n",
        "That thereby beauty's rose might never die,\n",
        "But as the riper should by time decease,\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "6c6a09e1-1a64-4113-9c5e-e5b311a56699",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c6a09e1-1a64-4113-9c5e-e5b311a56699",
        "outputId": "0d9e7f63-58fd-4147-d6f3-d8d858aaa736"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "127"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "len(part_stanza)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ad189c44-8715-4ec3-b975-a6dbd0a78fd9",
      "metadata": {
        "id": "ad189c44-8715-4ec3-b975-a6dbd0a78fd9"
      },
      "outputs": [],
      "source": [
        "seq_len = 120\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "6f68424c-12c2-479c-81d1-6e85a3c574ac",
      "metadata": {
        "id": "6f68424c-12c2-479c-81d1-6e85a3c574ac"
      },
      "outputs": [],
      "source": [
        "total_num_seq = len(text)//(seq_len+1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "5bc8849f-44f7-43af-945e-0496ee449593",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bc8849f-44f7-43af-945e-0496ee449593",
        "outputId": "9d4ed4ae-f2b3-4d51-b9cd-6f23cf174bff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45005"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "total_num_seq\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "299ec4ad-8f0b-446a-a769-bd65b7cc3823",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "299ec4ad-8f0b-446a-a769-bd65b7cc3823",
        "outputId": "f4a4de67-ab30-4eb7-f64b-afccdaddcbb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            "1\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "F\n",
            "r\n",
            "o\n",
            "m\n",
            " \n",
            "f\n",
            "a\n",
            "i\n",
            "r\n",
            "e\n",
            "s\n",
            "t\n",
            " \n",
            "c\n",
            "r\n",
            "e\n",
            "a\n",
            "t\n",
            "u\n",
            "r\n",
            "e\n",
            "s\n",
            " \n",
            "w\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            "s\n",
            "i\n",
            "r\n",
            "e\n",
            " \n",
            "i\n",
            "n\n",
            "c\n",
            "r\n",
            "e\n",
            "a\n",
            "s\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "a\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            "r\n",
            "e\n",
            "b\n",
            "y\n",
            " \n",
            "b\n",
            "e\n",
            "a\n",
            "u\n",
            "t\n",
            "y\n",
            "'\n",
            "s\n",
            " \n",
            "r\n",
            "o\n",
            "s\n",
            "e\n",
            " \n",
            "m\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "n\n",
            "e\n",
            "v\n",
            "e\n",
            "r\n",
            " \n",
            "d\n",
            "i\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "B\n",
            "u\n",
            "t\n",
            " \n",
            "a\n",
            "s\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "r\n",
            "i\n",
            "p\n",
            "e\n",
            "r\n",
            " \n",
            "s\n",
            "h\n",
            "o\n",
            "u\n",
            "l\n",
            "d\n",
            " \n",
            "b\n",
            "y\n",
            " \n",
            "t\n",
            "i\n",
            "m\n",
            "e\n",
            " \n",
            "d\n",
            "e\n",
            "c\n",
            "e\n",
            "a\n",
            "s\n",
            "e\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "H\n",
            "i\n",
            "s\n",
            " \n",
            "t\n",
            "e\n",
            "n\n",
            "d\n",
            "e\n",
            "r\n",
            " \n",
            "h\n",
            "e\n",
            "i\n",
            "r\n",
            " \n",
            "m\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "b\n",
            "e\n",
            "a\n",
            "r\n",
            " \n",
            "h\n",
            "i\n",
            "s\n",
            " \n",
            "m\n",
            "e\n",
            "m\n",
            "o\n",
            "r\n",
            "y\n",
            ":\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "B\n",
            "u\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "o\n",
            "u\n",
            " \n",
            "c\n",
            "o\n",
            "n\n",
            "t\n",
            "r\n",
            "a\n",
            "c\n",
            "t\n",
            "e\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "o\n",
            "w\n",
            "n\n",
            " \n",
            "b\n",
            "r\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            " \n",
            "e\n",
            "y\n",
            "e\n",
            "s\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "F\n",
            "e\n",
            "e\n",
            "d\n",
            "'\n",
            "s\n",
            "t\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "l\n",
            "i\n",
            "g\n",
            "h\n",
            "t\n",
            "'\n",
            "s\n",
            " \n",
            "f\n",
            "l\n",
            "a\n",
            "m\n",
            "e\n",
            " \n",
            "w\n",
            "i\n",
            "t\n",
            "h\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            "-\n",
            "s\n",
            "u\n",
            "b\n",
            "s\n",
            "t\n",
            "a\n",
            "n\n",
            "t\n",
            "i\n",
            "a\n",
            "l\n",
            " \n",
            "f\n",
            "u\n",
            "e\n",
            "l\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "M\n",
            "a\n",
            "k\n",
            "i\n",
            "n\n",
            "g\n",
            " \n",
            "a\n",
            " \n",
            "f\n",
            "a\n",
            "m\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "w\n",
            "h\n",
            "e\n",
            "r\n",
            "e\n",
            " \n",
            "a\n",
            "b\n",
            "u\n",
            "n\n",
            "d\n",
            "a\n",
            "n\n",
            "c\n",
            "e\n",
            " \n",
            "l\n",
            "i\n",
            "e\n",
            "s\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "y\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "f\n",
            "o\n",
            "e\n",
            ",\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "y\n",
            " \n",
            "s\n",
            "w\n",
            "e\n",
            "e\n",
            "t\n",
            " \n",
            "s\n",
            "e\n",
            "l\n",
            "f\n",
            " \n",
            "t\n",
            "o\n",
            "o\n",
            " \n",
            "c\n",
            "r\n",
            "u\n",
            "e\n",
            "l\n",
            ":\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "T\n",
            "h\n",
            "o\n",
            "u\n",
            " \n",
            "t\n",
            "h\n",
            "a\n",
            "t\n",
            " \n",
            "a\n",
            "r\n",
            "t\n",
            " \n",
            "n\n",
            "o\n",
            "w\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "w\n",
            "o\n",
            "r\n",
            "l\n",
            "d\n",
            "'\n",
            "s\n",
            " \n",
            "f\n",
            "r\n",
            "e\n",
            "s\n",
            "h\n",
            " \n",
            "o\n",
            "r\n",
            "n\n",
            "a\n",
            "m\n",
            "e\n",
            "n\n",
            "t\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "A\n",
            "n\n",
            "d\n",
            " \n",
            "o\n",
            "n\n",
            "l\n",
            "y\n",
            " \n",
            "h\n",
            "e\n",
            "r\n",
            "a\n",
            "l\n",
            "d\n",
            " \n",
            "t\n",
            "o\n",
            " \n",
            "t\n",
            "h\n",
            "e\n",
            " \n",
            "g\n",
            "a\n",
            "u\n",
            "d\n",
            "y\n",
            " \n",
            "s\n",
            "p\n",
            "r\n",
            "i\n",
            "n\n",
            "g\n",
            ",\n",
            "\n",
            "\n",
            " \n",
            " \n",
            "W\n",
            "i\n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            " \n",
            "t\n",
            "h\n",
            "i\n",
            "n\n",
            "e\n",
            " \n",
            "o\n",
            "w\n",
            "n\n",
            " \n",
            "b\n",
            "u\n"
          ]
        }
      ],
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
        "for i in char_dataset.take(500):\n",
        " print(ind_to_char[i.numpy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "c193bfa4-0901-42fb-b725-673f8d06d79a",
      "metadata": {
        "id": "c193bfa4-0901-42fb-b725-673f8d06d79a"
      },
      "outputs": [],
      "source": [
        "sequences = char_dataset.batch(seq_len+1, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "c711cee0-e044-4141-83df-813e3fcb09c9",
      "metadata": {
        "id": "c711cee0-e044-4141-83df-813e3fcb09c9"
      },
      "outputs": [],
      "source": [
        "def create_seq_targets(seq):\n",
        " input_txt = seq[:-1]\n",
        " target_txt = seq[1:]\n",
        " return input_txt, target_txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "70e3b465-870d-4219-8631-32cd49974ad3",
      "metadata": {
        "id": "70e3b465-870d-4219-8631-32cd49974ad3"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(create_seq_targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "5f03de9a-886c-4d4e-82db-3609a2a678f1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f03de9a-886c-4d4e-82db-3609a2a678f1",
        "outputId": "365ae220-b032-4bfd-c068-a9d902a5ea34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
            "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
            "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
            " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
            " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
            "\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But\n",
            "\n",
            "\n",
            "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
            "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
            " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
            " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
            "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
            "                     1\n",
            "  From fairest creatures we desire increase,\n",
            "  That thereby beauty's rose might never die,\n",
            "  But \n"
          ]
        }
      ],
      "source": [
        "for input_txt, target_txt in dataset.take(1):\n",
        " print(input_txt.numpy())\n",
        " print(''.join(ind_to_char[input_txt.numpy()]))\n",
        " print('\\n')\n",
        " print(target_txt.numpy())\n",
        " # There is an extra whitespace!\n",
        " print(''.join(ind_to_char[target_txt.numpy()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "1fa7298f-ce87-42b1-bd4b-85fe89916aaa",
      "metadata": {
        "id": "1fa7298f-ce87-42b1-bd4b-85fe89916aaa"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "buffer_size=10000\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "951c2e9b-b963-4e60-8a6c-1622ee58e003",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "951c2e9b-b963-4e60-8a6c-1622ee58e003",
        "outputId": "212a764d-e3bf-4822-ff53-d427a64fd2b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_BatchDataset element_spec=(TensorSpec(shape=(128, 120), dtype=tf.int64, name=None), TensorSpec(shape=(128, 120), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "01a01810-3ea1-4ad3-8682-e98bb2bad784",
      "metadata": {
        "id": "01a01810-3ea1-4ad3-8682-e98bb2bad784"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(vocab)\n",
        "# The embedding dimension\n",
        "embed_dim = 64\n",
        "# Number of RNN units\n",
        "rnn_neurons = 1026"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "35155e37-d69a-4b2b-ba6a-f1d7c462e13d",
      "metadata": {
        "id": "35155e37-d69a-4b2b-ba6a-f1d7c462e13d"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "da7c0811-a81e-46ab-a75b-d8fffdaccacf",
      "metadata": {
        "id": "da7c0811-a81e-46ab-a75b-d8fffdaccacf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "012bb546-c024-485f-adc9-1d960bfaa3db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "012bb546-c024-485f-adc9-1d960bfaa3db",
        "outputId": "41d61443-abcb-4037-ad81-8568aa4f41cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function sparse_categorical_crossentropy in module keras.src.losses.losses:\n",
            "\n",
            "sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, ignore_class=None, axis=-1)\n",
            "    Computes the sparse categorical crossentropy loss.\n",
            "    \n",
            "    Args:\n",
            "        y_true: Ground truth values.\n",
            "        y_pred: The predicted values.\n",
            "        from_logits: Whether `y_pred` is expected to be a logits tensor. By\n",
            "            default, we assume that `y_pred` encodes a probability distribution.\n",
            "        ignore_class: Optional integer. The ID of a class to be ignored during\n",
            "            loss computation. This is useful, for example, in segmentation\n",
            "            problems featuring a \"void\" class (commonly -1 or 255) in\n",
            "            segmentation maps. By default (`ignore_class=None`), all classes are\n",
            "            considered.\n",
            "        axis: Defaults to `-1`. The dimension along which the entropy is\n",
            "            computed.\n",
            "    \n",
            "    Returns:\n",
            "        Sparse categorical crossentropy loss value.\n",
            "    \n",
            "    Examples:\n",
            "    \n",
            "    >>> y_true = [1, 2]\n",
            "    >>> y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
            "    >>> loss = keras.losses.sparse_categorical_crossentropy(y_true, y_pred)\n",
            "    >>> assert loss.shape == (2,)\n",
            "    >>> loss\n",
            "    array([0.0513, 2.303], dtype=float32)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(sparse_categorical_crossentropy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "592b28f5-214c-4199-b31f-d926c3cf0d68",
      "metadata": {
        "id": "592b28f5-214c-4199-b31f-d926c3cf0d68"
      },
      "outputs": [],
      "source": [
        "def sparse_cat_loss(y_true,y_pred):\n",
        "    return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "744d1642-c304-479d-bf83-b4a937f9614b",
      "metadata": {
        "id": "744d1642-c304-479d-bf83-b4a937f9614b"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "298da4c9-a809-4677-96df-d7aece1cb43a",
      "metadata": {
        "id": "298da4c9-a809-4677-96df-d7aece1cb43a"
      },
      "outputs": [],
      "source": [
        "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, embed_dim, input_shape=(None,)))  # Updated\n",
        "    model.add(GRU(rnn_neurons, return_sequences=True, stateful=False, recurrent_initializer='glorot_uniform'))\n",
        "    model.add(Dense(vocab_size))  # Final Dense Layer to Predict\n",
        "\n",
        "    model.compile(optimizer='adam', loss=SparseCategoricalCrossentropy(from_logits=True))\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "a18beac4-dcfb-4efc-b255-880e5ace610d",
      "metadata": {
        "id": "a18beac4-dcfb-4efc-b255-880e5ace610d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e538c1-5b7b-4343-8076-1c1931226f3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = create_model(\n",
        "vocab_size = vocab_size,\n",
        "embed_dim = embed_dim,\n",
        "rnn_neurons = rnn_neurons,\n",
        "batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "4f267529-b869-49ba-b966-b98652ddb6a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "4f267529-b869-49ba-b966-b98652ddb6a9",
        "outputId": "8d26a59f-86c1-4a0b-acf7-71a0d81a1f9b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │           \u001b[38;5;34m5,376\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1026\u001b[0m)          │       \u001b[38;5;34m3,361,176\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)            │          \u001b[38;5;34m86,268\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,376</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1026</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,361,176</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">86,268</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,452,820\u001b[0m (13.17 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,452,820</span> (13.17 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,452,820\u001b[0m (13.17 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,452,820</span> (13.17 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "1b359d55-54c3-4ca8-98bd-24bf54c0d96d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b359d55-54c3-4ca8-98bd-24bf54c0d96d",
        "outputId": "ba54a7e2-e921-4dd5-91b9-0403650b42a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 120, 84) <=== (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    # Predict off some random batch\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "\n",
        "    # Display the dimensions of the predictions\n",
        "    print(example_batch_predictions.shape, \"<=== (batch_size, sequence_length, vocab_size)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "93228817-0480-4774-b3af-0badee98ee72",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93228817-0480-4774-b3af-0badee98ee72",
        "outputId": "da241594-f64f-459f-96f2-8ac2420ca462"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128, 120, 84), dtype=float32, numpy=\n",
              "array([[[-5.58208115e-03,  1.28024223e-03,  3.34105035e-03, ...,\n",
              "         -4.81383922e-03,  1.75696763e-03,  3.25372210e-03],\n",
              "        [-8.29128828e-03,  1.89030124e-03,  4.87125199e-03, ...,\n",
              "         -5.94118237e-03,  2.04968825e-03,  6.01144135e-03],\n",
              "        [-2.46363692e-04,  1.37694972e-03, -6.77539781e-03, ...,\n",
              "         -3.76831694e-03, -1.13943790e-03,  3.58141912e-03],\n",
              "        ...,\n",
              "        [ 2.83735734e-03, -6.64594304e-03,  2.10098748e-04, ...,\n",
              "          3.50674195e-03, -3.41921183e-03, -1.85761100e-03],\n",
              "        [ 6.22399850e-04,  2.49340571e-03,  4.67998500e-04, ...,\n",
              "         -3.09911557e-03, -4.00917651e-03, -1.62742901e-04],\n",
              "        [ 4.03299415e-03,  7.25791906e-04, -1.57554832e-03, ...,\n",
              "          5.90503542e-03,  5.74273337e-03,  2.91447941e-04]],\n",
              "\n",
              "       [[-5.58208115e-03,  1.28024223e-03,  3.34105035e-03, ...,\n",
              "         -4.81383922e-03,  1.75696763e-03,  3.25372210e-03],\n",
              "        [ 5.91353455e-04,  2.50101322e-04, -3.53288255e-04, ...,\n",
              "          6.12603826e-03,  8.71552154e-03,  2.49889563e-03],\n",
              "        [-1.83534261e-03,  2.85735191e-03, -6.01247186e-03, ...,\n",
              "         -1.17981469e-03, -1.43499626e-03,  1.80080777e-03],\n",
              "        ...,\n",
              "        [-2.29422236e-03,  9.79621080e-04, -1.11245429e-02, ...,\n",
              "         -1.48727419e-03, -7.64764613e-03,  6.91470876e-03],\n",
              "        [-2.51772930e-03,  2.72940355e-03, -1.24168135e-02, ...,\n",
              "         -7.14483904e-03, -1.11125130e-02,  3.81327793e-03],\n",
              "        [-5.67663321e-03, -3.95908952e-03, -5.01773041e-03, ...,\n",
              "         -3.50532751e-03, -1.69494841e-03,  5.08019514e-03]],\n",
              "\n",
              "       [[-5.58208115e-03,  1.28024223e-03,  3.34105035e-03, ...,\n",
              "         -4.81383922e-03,  1.75696763e-03,  3.25372210e-03],\n",
              "        [ 5.91353455e-04,  2.50101322e-04, -3.53288255e-04, ...,\n",
              "          6.12603826e-03,  8.71552154e-03,  2.49889563e-03],\n",
              "        [-1.54837733e-03, -4.37107496e-03,  6.73779359e-05, ...,\n",
              "          9.04065836e-03,  1.06697930e-02,  1.03475316e-03],\n",
              "        ...,\n",
              "        [-2.05825455e-03,  1.43896870e-03, -3.24916514e-03, ...,\n",
              "         -2.02193670e-03, -6.52329251e-03,  2.91504734e-03],\n",
              "        [ 1.45311130e-03,  6.34675706e-03, -2.00670050e-03, ...,\n",
              "         -2.67432013e-04, -4.61144466e-03,  2.45908042e-03],\n",
              "        [-4.11108648e-03,  5.74530289e-03,  1.71771902e-03, ...,\n",
              "         -5.37236221e-03, -1.40495831e-04,  5.31234220e-03]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-1.99599145e-03,  2.44454155e-03, -5.85531536e-03, ...,\n",
              "         -3.30508943e-03, -6.07865350e-03, -5.22287504e-04],\n",
              "        [-1.08337018e-03,  6.79463102e-03, -3.26413196e-03, ...,\n",
              "         -6.28848281e-03, -4.49171569e-03,  1.57744344e-03],\n",
              "        [-5.35267405e-03, -2.25690403e-03,  5.44047653e-05, ...,\n",
              "         -4.14938171e-04,  2.53582653e-03,  3.94329103e-03],\n",
              "        ...,\n",
              "        [-1.22069451e-03,  3.85947037e-03, -6.45152479e-03, ...,\n",
              "         -3.23349051e-03, -1.40614319e-03,  1.97800761e-03],\n",
              "        [-2.95609399e-03,  1.05499756e-03, -1.11606663e-04, ...,\n",
              "          8.74679390e-05, -2.75713787e-03,  4.74436581e-03],\n",
              "        [-5.80497039e-03,  9.47626017e-04, -1.71931821e-03, ...,\n",
              "          9.23567743e-04, -4.78088530e-03,  9.18124244e-03]],\n",
              "\n",
              "       [[ 8.02710128e-04, -4.17840434e-03,  4.04875772e-03, ...,\n",
              "         -2.33482430e-03, -1.16351782e-03,  2.18447275e-03],\n",
              "        [ 9.08663147e-04, -5.00931870e-03,  5.85641759e-03, ...,\n",
              "         -3.30227986e-03, -2.22087651e-03,  3.07006808e-03],\n",
              "        [ 8.82225763e-03, -3.58249107e-03,  6.01645978e-03, ...,\n",
              "          3.27523542e-03, -3.30059580e-03,  3.14885378e-03],\n",
              "        ...,\n",
              "        [-1.67421740e-03,  7.90356472e-03, -1.22660613e-02, ...,\n",
              "         -1.07850106e-02, -1.34737799e-02,  2.72084447e-03],\n",
              "        [-1.67421764e-03,  7.90356752e-03, -1.22660585e-02, ...,\n",
              "         -1.07850125e-02, -1.34737780e-02,  2.72084540e-03],\n",
              "        [ 3.27088265e-03,  7.31942337e-03, -6.04538945e-03, ...,\n",
              "         -8.27721693e-03, -1.12803169e-02, -2.71796412e-03]],\n",
              "\n",
              "       [[ 2.04090076e-03,  3.27559141e-03, -2.35961936e-03, ...,\n",
              "         -2.06842157e-03, -1.92047970e-03,  1.82895036e-03],\n",
              "        [-1.17424910e-03,  5.00235427e-03, -8.21837969e-03, ...,\n",
              "         -5.77699766e-03, -5.40350610e-03,  4.64760204e-04],\n",
              "        [-1.77304377e-03,  9.83029022e-05, -1.01088928e-02, ...,\n",
              "         -1.32875895e-04, -3.37447366e-03,  5.31352218e-03],\n",
              "        ...,\n",
              "        [-1.86398090e-03,  1.45509327e-03, -5.68736345e-03, ...,\n",
              "         -6.14800118e-03, -9.76586714e-03, -3.72149312e-04],\n",
              "        [ 3.29677854e-03, -1.28135306e-03, -1.84546504e-03, ...,\n",
              "         -7.73587311e-03, -4.93635377e-03, -8.49047501e-04],\n",
              "        [ 1.05012851e-02, -2.05824757e-03,  8.25682073e-04, ...,\n",
              "         -6.01591018e-04, -3.19469697e-03,  3.30711342e-03]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "example_batch_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "e8c4b68c-b5ff-4649-816b-4cfcb9792be3",
      "metadata": {
        "id": "e8c4b68c-b5ff-4649-816b-4cfcb9792be3"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "64d2fd4e-2cc2-4fbb-bcc7-537b88c37881",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64d2fd4e-2cc2-4fbb-bcc7-537b88c37881",
        "outputId": "26294264-b8f4-43f4-9fc7-7baa99719189"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(120, 1), dtype=int64, numpy=\n",
              "array([[38],\n",
              "       [23],\n",
              "       [82],\n",
              "       [ 7],\n",
              "       [68],\n",
              "       [28],\n",
              "       [53],\n",
              "       [25],\n",
              "       [58],\n",
              "       [ 6],\n",
              "       [31],\n",
              "       [65],\n",
              "       [55],\n",
              "       [ 7],\n",
              "       [37],\n",
              "       [27],\n",
              "       [30],\n",
              "       [66],\n",
              "       [59],\n",
              "       [68],\n",
              "       [59],\n",
              "       [ 1],\n",
              "       [28],\n",
              "       [65],\n",
              "       [11],\n",
              "       [ 2],\n",
              "       [76],\n",
              "       [82],\n",
              "       [41],\n",
              "       [ 4],\n",
              "       [40],\n",
              "       [29],\n",
              "       [46],\n",
              "       [21],\n",
              "       [11],\n",
              "       [57],\n",
              "       [74],\n",
              "       [36],\n",
              "       [42],\n",
              "       [31],\n",
              "       [80],\n",
              "       [53],\n",
              "       [14],\n",
              "       [25],\n",
              "       [36],\n",
              "       [ 1],\n",
              "       [11],\n",
              "       [39],\n",
              "       [79],\n",
              "       [35],\n",
              "       [29],\n",
              "       [65],\n",
              "       [60],\n",
              "       [57],\n",
              "       [23],\n",
              "       [57],\n",
              "       [69],\n",
              "       [80],\n",
              "       [65],\n",
              "       [45],\n",
              "       [80],\n",
              "       [ 1],\n",
              "       [27],\n",
              "       [39],\n",
              "       [74],\n",
              "       [23],\n",
              "       [35],\n",
              "       [30],\n",
              "       [17],\n",
              "       [57],\n",
              "       [78],\n",
              "       [51],\n",
              "       [41],\n",
              "       [55],\n",
              "       [ 9],\n",
              "       [20],\n",
              "       [70],\n",
              "       [33],\n",
              "       [ 8],\n",
              "       [49],\n",
              "       [14],\n",
              "       [55],\n",
              "       [71],\n",
              "       [61],\n",
              "       [10],\n",
              "       [72],\n",
              "       [72],\n",
              "       [ 9],\n",
              "       [17],\n",
              "       [ 1],\n",
              "       [74],\n",
              "       [14],\n",
              "       [14],\n",
              "       [29],\n",
              "       [14],\n",
              "       [37],\n",
              "       [ 8],\n",
              "       [39],\n",
              "       [67],\n",
              "       [39],\n",
              "       [45],\n",
              "       [59],\n",
              "       [76],\n",
              "       [55],\n",
              "       [31],\n",
              "       [83],\n",
              "       [64],\n",
              "       [32],\n",
              "       [56],\n",
              "       [65],\n",
              "       [76],\n",
              "       [40],\n",
              "       [75],\n",
              "       [30],\n",
              "       [67],\n",
              "       [ 8],\n",
              "       [62],\n",
              "       [69],\n",
              "       [27],\n",
              "       [74]])>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "sampled_indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "7aa1139e-7b0b-4dd1-b5fe-fc81ed919434",
      "metadata": {
        "id": "7aa1139e-7b0b-4dd1-b5fe-fc81ed919434"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "85af1245-9cfa-4006-9afb-716d4a312b44",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85af1245-9cfa-4006-9afb-716d4a312b44",
        "outputId": "28d0407f-3b45-4153-ffb9-77efcaa013fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([38, 23, 82,  7, 68, 28, 53, 25, 58,  6, 31, 65, 55,  7, 37, 27, 30,\n",
              "       66, 59, 68, 59,  1, 28, 65, 11,  2, 76, 82, 41,  4, 40, 29, 46, 21,\n",
              "       11, 57, 74, 36, 42, 31, 80, 53, 14, 25, 36,  1, 11, 39, 79, 35, 29,\n",
              "       65, 60, 57, 23, 57, 69, 80, 65, 45, 80,  1, 27, 39, 74, 23, 35, 30,\n",
              "       17, 57, 78, 51, 41, 55,  9, 20, 70, 33,  8, 49, 14, 55, 71, 61, 10,\n",
              "       72, 72,  9, 17,  1, 74, 14, 14, 29, 14, 37,  8, 39, 67, 39, 45, 59,\n",
              "       76, 55, 31, 83, 64, 32, 56, 65, 76, 40, 75, 30, 67,  8, 62, 69, 27,\n",
              "       74])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "fe98040c-b68e-4b0c-911e-415bb938f96f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe98040c-b68e-4b0c-911e-415bb938f96f",
        "outputId": "9c2c001f-b614-4267-b3e3-680ddbe0208f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given the input seq: \n",
            "\n",
            "eep't back again.\n",
            "  MENAS. Y'have said, sir. We look'd not for Mark Antony here. Pray\n",
            "    you, is he married to Cleopatr\n",
            "\n",
            "\n",
            "Next Char Predictions: \n",
            "\n",
            "M<|)mC]?c(Fj`)LBEkdmd Cj0!u|P&ODU:0bsKQFy]3?K 0NxJDjeb<bnyjTy BNs<JE6bwZP`-9oH,X3`pf.qq-6 s33D3L,NlNTdu`F}iGajuOtEl,gnBs\n"
          ]
        }
      ],
      "source": [
        "print(\"Given the input seq: \\n\")\n",
        "print(\"\".join(ind_to_char[input_example_batch[0]]))\n",
        "print('\\n')\n",
        "print(\"Next Char Predictions: \\n\")\n",
        "print(\"\".join(ind_to_char[sampled_indices ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "f45fb1d8-77dc-4fee-abc6-991439425cd1",
      "metadata": {
        "id": "f45fb1d8-77dc-4fee-abc6-991439425cd1"
      },
      "outputs": [],
      "source": [
        "epochs = 30\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "0c3fe0a3-d58e-4473-8f10-299279ef9985",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c3fe0a3-d58e-4473-8f10-299279ef9985",
        "outputId": "7e6c8f3c-ca7d-463b-a127-bc04c8dfacbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 134ms/step - loss: 2.8827\n",
            "Epoch 2/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 141ms/step - loss: 1.6128\n",
            "Epoch 3/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 139ms/step - loss: 1.3715\n",
            "Epoch 4/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 140ms/step - loss: 1.2729\n",
            "Epoch 5/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 140ms/step - loss: 1.2159\n",
            "Epoch 6/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 140ms/step - loss: 1.1783\n",
            "Epoch 7/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 140ms/step - loss: 1.1488\n",
            "Epoch 8/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 140ms/step - loss: 1.1239\n",
            "Epoch 9/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 142ms/step - loss: 1.1032\n",
            "Epoch 10/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 138ms/step - loss: 1.0847\n",
            "Epoch 11/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 141ms/step - loss: 1.0677\n",
            "Epoch 12/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 140ms/step - loss: 1.0520\n",
            "Epoch 13/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 140ms/step - loss: 1.0347\n",
            "Epoch 14/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 143ms/step - loss: 1.0200\n",
            "Epoch 15/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 138ms/step - loss: 1.0073\n",
            "Epoch 16/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 140ms/step - loss: 0.9924\n",
            "Epoch 17/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 142ms/step - loss: 0.9815\n",
            "Epoch 18/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 138ms/step - loss: 0.9683\n",
            "Epoch 19/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 141ms/step - loss: 0.9577\n",
            "Epoch 20/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 140ms/step - loss: 0.9465\n",
            "Epoch 21/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 143ms/step - loss: 0.9358\n",
            "Epoch 22/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 138ms/step - loss: 0.9286\n",
            "Epoch 23/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 141ms/step - loss: 0.9208\n",
            "Epoch 24/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 139ms/step - loss: 0.9122\n",
            "Epoch 25/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 143ms/step - loss: 0.9059\n",
            "Epoch 26/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 141ms/step - loss: 0.9014\n",
            "Epoch 27/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 142ms/step - loss: 0.8966\n",
            "Epoch 28/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 138ms/step - loss: 0.8918\n",
            "Epoch 29/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 141ms/step - loss: 0.8896\n",
            "Epoch 30/30\n",
            "\u001b[1m351/351\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 142ms/step - loss: 0.8865\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x780cb9ace2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "model.fit(dataset,epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "78a75c9f-b6b6-46b1-9063-1e993b19a345",
      "metadata": {
        "id": "78a75c9f-b6b6-46b1-9063-1e993b19a345",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44afcfd5-053f-46e1-c791-a91684c1517d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save('shakespeare_gen.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "mkrNpdGSa_4I"
      },
      "id": "mkrNpdGSa_4I",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n",
        "model.load_weights('shakespeare_gen.h5')\n",
        "model.build(tf.TensorShape([None, None]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cknvpiXTbIud",
        "outputId": "15256529-73f3-479a-9138-87af44a11d9b"
      },
      "id": "cknvpiXTbIud",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "IY1F0i0DbJue",
        "outputId": "56107bfe-8f10-4c35-d312-70c543256ef7"
      },
      "id": "IY1F0i0DbJue",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │           \u001b[38;5;34m5,376\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1026\u001b[0m)          │       \u001b[38;5;34m3,361,176\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)            │          \u001b[38;5;34m86,268\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,376</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1026</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,361,176</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">86,268</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,452,820\u001b[0m (13.17 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,452,820</span> (13.17 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,452,820\u001b[0m (13.17 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,452,820</span> (13.17 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_seed,gen_size=100,temp=1.0):\n",
        " '''\n",
        " model: Trained Model to Generate Text\n",
        " start_seed: Intial Seed text in string form\n",
        " gen_size: Number of characters to generate\n",
        " Basic idea behind this function is to take in some seed text, format it so\n",
        " that it is in the correct shape for our network, then loop the sequence as\n",
        " we keep adding our own predicted characters. Similar to our work in the RNN\n",
        " time series problems.\n",
        " '''\n",
        " # Number of characters to generate\n",
        " num_generate = gen_size\n",
        " # Vecotrizing starting seed text\n",
        " input_eval = [char_to_ind[s] for s in start_seed]\n",
        " # Expand to match batch format shape\n",
        " input_eval = tf.expand_dims(input_eval, 0)\n",
        " # Empty list to hold resulting generated text\n",
        " text_generated = []\n",
        " # Temperature effects randomness in our resulti\n",
        " # The term is derived from entropy/thermodynamics.\n",
        " # The temperature is used to effect probability of next characters.\n",
        " # Higher probability == lesss surprising/ more expected\n",
        " # Lower temperature == more surprising / less expected\n",
        " temperature = temp\n",
        " # Here batch size == 1\n",
        " # model.reset_states()\n",
        " for i in range(num_generate):\n",
        "  # Generate Predictions\n",
        "  predictions = model(input_eval)\n",
        "  # Remove the batch shape dimension\n",
        "  predictions = tf.squeeze(predictions, 0)\n",
        "  # Use a cateogircal disitribution to select the next character\n",
        "  predictions = predictions / temperature\n",
        "  predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "  # Pass the predicted charracter for the next input\n",
        "  input_eval = tf.expand_dims([predicted_id], 0)\n",
        "  # Transform back to character letter\n",
        "  text_generated.append(ind_to_char[predicted_id])\n",
        " return (start_seed + ''.join(text_generated))\n"
      ],
      "metadata": {
        "id": "J3FfB7rEbMU5"
      },
      "id": "J3FfB7rEbMU5",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(model,\"flower\",gen_size=1000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwtGUb88cTr_",
        "outputId": "29444fd4-2bea-4c55-a030-109e6809fa41"
      },
      "id": "FwtGUb88cTr_",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "flowerstotan   tllareee   nooime oofand  pr tou   Louche\n",
            "   E alot   alfourt ckniak: tcaless hyond  SSE  tofl, o a  As  Paveaits us ine\n",
            " s, n ay  PHI hamongue th, IORIN. gofit.\n",
            " go akee. dsavetl tams tary  me,    NThey TEDris. d she torave'sif HIANGowisefurut LA\n",
            " othit the n    o, pldewery'se  tange. LUKS\n",
            " y   irord   tsidok's'sul forse.\n",
            "\n",
            "   INGHes.\n",
            " bes   heactt    sidindo PRSEThyofughive  harsa-\n",
            " d,\n",
            " mithain  Hofof, PLWhest; gher NON. sththorave, thipe BACOS: tt H. p llly    mer otithand t EN. crnory.\n",
            " BAdeer VAmyold7\n",
            " ant   PamescTRIZod,  le  barou   ame, me   sowiesthem NI     m\n",
            " wno'd he\n",
            "   T\n",
            "<TILellourno? shamalof ist k\n",
            " oan UEKETIMAntaurme I lonold whocomanontheshothar y lir,\n",
            " whis   peris? ime ma he,     to-\n",
            " ke Ju s Mase nd  tr)\n",
            " tiserd  s?\n",
            " an, th ith  thait himilougaungas?\n",
            "     wodie ator \n",
            " h    k   wisas IRVave. f thtoule r  d  TILO I t  we   inghan T.\n",
            " t\n",
            "   wndest \n",
            "    d  weshiset. ker  fis Pry yporandof s mit Goleacef tofoutst. ouer re? tollye\n",
            "  Itu n I ins a\n",
            " man'd in's s oryo\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}